{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from UnionFind import UnionFind\n",
    "import pickle\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207885\n"
     ]
    }
   ],
   "source": [
    "label_path = 'data/labels.csv'\n",
    "\n",
    "filtered_path = 'data/filtered.csv'\n",
    "filtered_list = []\n",
    "\n",
    "df = pd.read_csv(label_path)\n",
    "\n",
    "label_list = np.array(df['title'])\n",
    "id_list = np.array(df['id'])\n",
    "\n",
    "for label, p_id in zip(label_list, id_list):\n",
    "    if label != '[]' and 'Movies' in label:\n",
    "        filtered_list.append(p_id)\n",
    "print(len(filtered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(filtered_list,index=None, columns=['p_id']).to_csv(filtered_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        save_path,\n",
    "        prime_video_path,\n",
    "        label_path,\n",
    "        deduplicate_path,\n",
    "        file_list,\n",
    "        file_path,\n",
    "        pv_filter_path,\n",
    "        label_filter_path\n",
    "    ):\n",
    "        # init path\n",
    "        self._uf_dict = pickle.load(open(deduplicate_path, 'rb'))\n",
    "        self._save_path = save_path\n",
    "        self._pv_path = prime_video_path\n",
    "        self._label_path = label_path\n",
    "        self._deduplicate_path = deduplicate_path\n",
    "        self._file_list = file_list\n",
    "        self._file_path = file_path\n",
    "        self._pv_filter_path = pv_filter_path\n",
    "        self._label_filter_path = label_filter_path\n",
    "        # filter\n",
    "        self._filtered_list = []\n",
    "        self.get_deduplicate_list()\n",
    "        final = np.union1d(self.filter_by_label(),self.filter_prime_video())\n",
    "        print('[final]: ', final)\n",
    "        \n",
    "    def get_deduplicate_list(self):\n",
    "        for index, key in enumerate(self._uf_dict):\n",
    "            if key == sorted(list(self._uf_dict[key]))[0]:\n",
    "                self._filtered_list.append(key)\n",
    "        self._filtered_list = np.array(self._filtered_list)\n",
    "        print('[length of deduplicate_list]: ', len(self._filtered_list))\n",
    "            \n",
    "    def filter_by_label(self, reCalculate=False):\n",
    "        # 注意，这个过滤器基于deduplicate后的filtered_list\n",
    "        # 注意，这个过滤器会滤掉所有prime video\n",
    "        if reCalculate:\n",
    "            tmp_list = []\n",
    "            df = pd.read_csv(self._label_path)\n",
    "            label_list = np.array(df['title'])\n",
    "            id_list = np.array(df['id'])\n",
    "            for label, p_id in zip(label_list, id_list):\n",
    "                if label != '[]' and 'Movies' in label and p_id in self._filtered_list:\n",
    "                    tmp_list.append(p_id)\n",
    "            ans = np.intersect1d(np.array(self._filtered_list), np.array(tmp_list)) \n",
    "            print('[length of filtered_list by label]: ', ans.shape)\n",
    "            pd.DataFrame(ans,index=None, columns=['p_id']).to_csv(self._label_filter_path)\n",
    "            print('finish write to label_filter_list.csv')\n",
    "            return ans\n",
    "        else:\n",
    "            return np.array(pd.read_csv(self._label_filter_path)['p_id'])\n",
    "\n",
    "        \n",
    "    def filter_prime_video(self, reCalculate=False):\n",
    "        # 注意，这个过滤器基于deduplicate后的filtered_list\n",
    "        # 注意，这个过滤器只能保留prime video\n",
    "        if reCalculate:\n",
    "\n",
    "            tmp_list = []\n",
    "            prime_video_list = np.array(pd.read_csv(self._pv_path)['p_id'])\n",
    "            print(prime_video_list.shape)\n",
    "            for index, file_name in enumerate(self._file_list):\n",
    "                if index % 5000 == 0:\n",
    "                    print('[index]:', index)          \n",
    "                ct_id = file_name.split('.')[0][-10:]\n",
    "                if ct_id in prime_video_list and ct_id in self._filtered_list:      \n",
    "                    # 解析html文件\n",
    "                    content = open(self._file_path+'/'+file_name, 'r').read()\n",
    "                    soup = BeautifulSoup(content, 'lxml')\n",
    "                    try:\n",
    "                        div = str(soup.find(id=\"dv-action-box-wrapper\"))\n",
    "                        if 'titleType=movie' in div:\n",
    "                            tmp_list.append(ct_id)\n",
    "                    except :\n",
    "                        pass\n",
    "            print('[length of filtered_list by prime video]: ', len(tmp_list))\n",
    "            pd.DataFrame(np.array(tmp_list),index=None, columns=['p_id']).to_csv(self._pv_filter_path)\n",
    "            print('finish write to pv_filter_list.csv')\n",
    "            return np.array(tmp_list)\n",
    "        else:\n",
    "            return np.array(pd.read_csv(self._pv_filter_path)['p_id'])\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[length of deduplicate_list]:  167893\n",
      "[length of filtered_list by label]:  (131159,)\n",
      "finish write to label_filter_list.csv\n",
      "(35226,)\n",
      "[index]: 0\n",
      "[index]: 5000\n",
      "[index]: 10000\n",
      "[index]: 15000\n",
      "[index]: 20000\n",
      "[index]: 25000\n",
      "[index]: 30000\n",
      "[index]: 35000\n",
      "[index]: 40000\n",
      "[index]: 45000\n",
      "[index]: 50000\n",
      "[index]: 55000\n",
      "[index]: 60000\n",
      "[index]: 65000\n",
      "[index]: 70000\n",
      "[index]: 75000\n",
      "[index]: 80000\n",
      "[index]: 85000\n",
      "[index]: 90000\n",
      "[index]: 95000\n",
      "[index]: 100000\n",
      "[index]: 105000\n",
      "[index]: 110000\n",
      "[index]: 115000\n",
      "[index]: 120000\n",
      "[index]: 125000\n",
      "[index]: 130000\n",
      "[index]: 135000\n",
      "[index]: 140000\n",
      "[index]: 145000\n",
      "[index]: 150000\n",
      "[index]: 155000\n",
      "[index]: 160000\n",
      "[index]: 165000\n",
      "[index]: 170000\n",
      "[index]: 175000\n",
      "[index]: 180000\n",
      "[index]: 185000\n",
      "[index]: 190000\n",
      "[index]: 195000\n",
      "[index]: 200000\n",
      "[index]: 205000\n",
      "[index]: 210000\n",
      "[index]: 215000\n",
      "[index]: 220000\n",
      "[index]: 225000\n",
      "[index]: 230000\n",
      "[index]: 235000\n",
      "[index]: 240000\n",
      "[index]: 245000\n",
      "[index]: 250000\n",
      "[length of filtered_list by prime video]:  25049\n",
      "finish write to pv_filter_list.csv\n"
     ]
    }
   ],
   "source": [
    "path = '/media/googlecamp/Teclast_S301/zips/_unzip'  # 待读取文件的文件夹绝对地址\n",
    "f_list = os.listdir(path)  # 获得文件夹中所有文件的名称列表\n",
    "label_path = 'data/labels.csv'\n",
    "save_path = 'data/filtered.csv'\n",
    "deduplicate_path = 'data/UFMap/component_mapping.pickle'\n",
    "prime_video_path = 'data/ErrorPages/error_id_list.csv'\n",
    "pv_filter_path = 'data/pv_filter_list.csv'\n",
    "label_filter_path = 'data/label_filter_list.csv'\n",
    "filter = Filter(save_path, prime_video_path, label_path, deduplicate_path, f_list, path, pv_filter_path, label_filter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[length of deduplicate_list]:  167893\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/label_filter_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9a33e6efb7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpv_filter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/pv_filter_list.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlabel_filter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/label_filter_list.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeduplicate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpv_filter_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_filter_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-6f4b936e8fff>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, save_path, prime_video_path, label_path, deduplicate_path, file_list, file_path, pv_filter_path, label_filter_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deduplicate_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_prime_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[final]: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6f4b936e8fff>\u001b[0m in \u001b[0;36mfilter_by_label\u001b[0;34m(self, reCalculate)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_filter_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dw/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dw/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dw/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dw/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dw/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/label_filter_list.csv'"
     ]
    }
   ],
   "source": [
    "path = '/media/googlecamp/Teclast_S301/zips/_unzip'  # 待读取文件的文件夹绝对地址\n",
    "f_list = os.listdir(path)  # 获得文件夹中所有文件的名称列表\n",
    "label_path = 'data/labels.csv'\n",
    "save_path = 'data/filtered.csv'\n",
    "deduplicate_path = 'data/UFMap/component_mapping.pickle'\n",
    "prime_video_path = 'data/ErrorPages/error_id_list.csv'\n",
    "pv_filter_path = 'data/pv_filter_list.csv'\n",
    "label_filter_path = 'data/label_filter_list.csv'\n",
    "filter = Filter(save_path, prime_video_path, label_path, deduplicate_path, f_list, path, pv_filter_path, label_filter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dw",
   "language": "python",
   "name": "dw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
