{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from UnionFind import UnionFind\n",
    "import pickle\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_path = 'data/imdb_movies.csv'\n",
    "filtered_path = 'data/filtered.csv'\n",
    "# web file\n",
    "path = '/media/googlecamp/Teclast_S301/zips/_unzip'  # 待读取文件的文件夹绝对地址\n",
    "f_list = os.listdir(path)  # 获得文件夹中所有文件的名称列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_title_list(imdb_path):\n",
    "    return np.array(pd.read_csv(imdb_path)['title'])\n",
    "\n",
    "def get_filtered_list(filtered_path):\n",
    "    return np.array(pd.read_csv(filtered_path)['p_id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85855,)\n",
      "(207885,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/googlecamp/anaconda3/envs/dw/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "imdb_title_list = get_imdb_title_list(imdb_path)\n",
    "filtered_list = get_filtered_list(filtered_path)\n",
    "print(imdb_title_list.shape)\n",
    "print(filtered_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_scores(file_list, file_path, imdb_title_list, filtered_list):\n",
    "    scores_list = [-1 for i in range(len(file_list))]\n",
    "    print(len(scores_list))\n",
    "    for index, file_name in enumerate(file_list):\n",
    "        if index == 10:\n",
    "            break\n",
    "        ct_id = file_name.split('.')[0][-10:]\n",
    "        if ct_id in filtered_list:\n",
    "            print('*'*10)\n",
    "            print('[ct_id]: ', ct_id, ' in filtered_list')\n",
    "            # 解析html文件\n",
    "            content = open(file_path+'/'+file_name, 'r').read()\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            # 获取当前title\n",
    "            try:\n",
    "                #\n",
    "                spans = soup.find_all(id=\"productTitle\")\n",
    "                for span in spans:\n",
    "                    ct_title = span.string.replace('\\n', '')\n",
    "                    ct_title = ct_title.split('(')[0]\n",
    "                    ct_title = ct_title.split('[')[0]\n",
    "                    ans = process.extractOne(ct_title, imdb_title_list)\n",
    "                    print('[ct_title]: ', ct_title)\n",
    "                    print('[best match]: ', ans[0])\n",
    "                    print('[score]: ', ans[1])\n",
    "                print('*'*10)\n",
    "                # 遍历a_list\n",
    "\n",
    "            except :\n",
    "                print('error')\n",
    "        else:\n",
    "            print('[ct_id]: ', ct_id, ' not in')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251668\n",
      "**********\n",
      "[ct_id]:  B00006L974  in filtered_list\n",
      "[ct_title]:  Voodoo Tailz \n",
      "[best match]:  Voodoo\n",
      "[score]:  90\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  B00006L977  in filtered_list\n",
      "[ct_title]:  Reign in Darkness \n",
      "[best match]:  Darkness\n",
      "[score]:  90\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  B00006L979  in filtered_list\n",
      "[ct_title]:  The Dead Zone \n",
      "[best match]:  The Dead One\n",
      "[score]:  96\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  6302031966  in filtered_list\n",
      "[ct_title]:  Stigma \n",
      "[best match]:  Stigma\n",
      "[score]:  100\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  B00005U16X  in filtered_list\n",
      "[ct_title]:  Bully \n",
      "[best match]:  Bully\n",
      "[score]:  100\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  1932228160  in filtered_list\n",
      "[ct_title]:  I Was a Teenage Faust \n",
      "[best match]:  Faust\n",
      "[score]:  90\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  6301952235  in filtered_list\n",
      "[ct_title]:  Alligator Eyes \n",
      "[best match]:  Alligator Eyes\n",
      "[score]:  100\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  B004XWBOWE  in filtered_list\n",
      "[ct_title]:  2012 & Beyond: The Illuminati Plan - Volume 1 of 2\n",
      "[best match]:  The Story of the Kelly Gang\n",
      "[score]:  86\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  6302286875  in filtered_list\n",
      "[ct_title]:  Bicycle Thief \n",
      "[best match]:  Cycle\n",
      "[score]:  90\n",
      "**********\n",
      "**********\n",
      "[ct_id]:  B003WUYO3O  in filtered_list\n",
      "[ct_title]:  Namibia Land of Contrast\n",
      "[best match]:  Lan\n",
      "[score]:  90\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "get_all_scores(file_list=f_list, file_path=path, imdb_title_list=imdb_title_list, filtered_list=filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_titles(file_list, file_path, imdb_title_list, filtered_list):\n",
    "    # 新建 dataFrame\n",
    "    df = pd.Dataframe(columns=[\"p_id\", \"title\"])\n",
    "    error_df = pd.Dataframe(columns=[\"p_id\"])\n",
    "    # 遍历 file获取title\n",
    "    for index, file_name in enumerate(file_list):\n",
    "        # 测试代码\n",
    "        if index % 10 == 9:\n",
    "            df.to_csv('/data/titles_list.csv')\n",
    "            error_df.to_csv('/data/error_titles_list.csv')\n",
    "            break\n",
    "        ct_id = file_name.split('.')[0][-10:]\n",
    "        # label需要符合要求\n",
    "        if ct_id in filtered_list:\n",
    "            print('[ct_id]: ', ct_id, ' in filtered_list')\n",
    "            # 解析html文件\n",
    "            content = open(file_path+'/'+file_name, 'r').read()\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            # 获取当前title\n",
    "            try:\n",
    "                spans = soup.find_all(id=\"productTitle\")\n",
    "                ct_title = spans[0].string.replace('\\n', '')\n",
    "                ct_title = ct_title.split('(')[0]\n",
    "                ct_title = ct_title.split('[')[0]\n",
    "                df = df.append(pd.DataFrame({'p_id':[ct_id], 'title':[ct_title]}),ignore_index=True)\n",
    "            except :\n",
    "                error_df = error_df.append(pd.DataFrame({'p_id':[ct_id]}),ignore_index=True)\n",
    "        else:\n",
    "            print('[ct_id]: ', ct_id, ' not in')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dw",
   "language": "python",
   "name": "dw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
